# -*- coding: utf-8 -*-
"""tfp_test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r2CFF7Zfwj8muLWg90KNDA_fnIK3gqBj
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow.compat.v2 as tf
import tensorflow_probability as tfp
from mpl_toolkits.mplot3d import Axes3D
from google.colab import files
import io

uploaded = files.upload()

def mean_fn(index_points):
  return tf.reshape(3*index_points, shape=[int(len(index_points))/2, 2])

data = np.array(pd.read_csv(io.BytesIO(uploaded['gyro_fake_data_v1.csv'])))

tf.enable_v2_behavior()

tfb = tfp.bijectors
tfd = tfp.distributions
psd_kernels = tfp.math.psd_kernels

# observations from a known function at some random points.

Y = Y_plot = data[::100,1].reshape(-1,1)
Y_new = data[::100,1]
X1 = X1_plot = data[::100,3] #rotation
X2 = X2_plot = data[::100,2] #B_V
X = np.dstack([X1, X2]).reshape(-1, 2)

y1 = Y_new
y2 = Y_new

observation_index_points = X 
observations = Y.T #np.dstack([y1,y2]).reshape(-1, 2)

x1_mesh, x2_mesh = np.meshgrid(X1, X2)

resolution = len(Y)
X1_test = np.linspace( np.min(X1), np.max(X1), num=resolution )
X2_test = np.linspace( np.min(X2), np.max(X2), num=resolution )
X1_test, X2_test = np.meshgrid( X1_test, X2_test )
X_test = np.dstack([X1_test, X2_test]).reshape(resolution, resolution, 2)
observation_noise_variance = np.ones(resolution).reshape(-1,1)

print(observation_index_points.shape, observations.shape)
amplitude = tfp.util.TransformedVariable(
  1., tfb.Exp(), dtype=tf.float64, name='amplitude')
length_scale = tfp.util.TransformedVariable(
  1., tfb.Exp(), dtype=tf.float64, name='length_scale')
kernel = psd_kernels.ExponentiatedQuadratic(amplitude, length_scale)

#observation_noise_variance = tfp.util.TransformedVariable(
#    np.exp(-5), tfb.Exp(), name='observation_noise_variance')

optimizer = tf.optimizers.Adam(learning_rate=.05, beta_1=.5, beta_2=.99)

@tf.function
def optimize():
  with tf.GradientTape() as tape:
    loss = -gp.log_prob(observations)
  grads = tape.gradient(loss, gp.trainable_variables)
  optimizer.apply_gradients(zip(grads, gp.trainable_variables))
  return loss

gp = tfd.GaussianProcessRegressionModel(
    kernel=kernel,
    index_points=X_test,
    observation_index_points=X,
    observations=Y.T, mean_fn=mean_fn)

for i in range(1000):
  neg_log_likelihood_ = optimize()

samples = gp.sample(10)
# ==> 10 independently drawn, joint samples at `index_points`.
# ==> 10 independently drawn, noisy joint samples at `index_points`

fig = plt.figure(figsize=(18, 10))
ax = plt.axes(projection='3d')
ax.view_init(0, 40)
ax.plot_surface(X1_test, X2_test, samples[0], antialiased=True, alpha=0.7, linewidth=0.5, cmap='winter')
ax.scatter3D(X1, X2, Y, marker='o',edgecolors='k', color='r', s=150)
ax.set_xlabel('B-V Index')
ax.set_ylabel('Rotation Period (Days)')
ax.set_zlabel('Age (Gyr)')

plt.show()