# -*- coding: utf-8 -*-
"""tfp_test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r2CFF7Zfwj8muLWg90KNDA_fnIK3gqBj
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow.compat.v2 as tf
import tensorflow_probability as tfp
from mpl_toolkits.mplot3d import Axes3D
# from google.colab import files
# import io

# uploaded = files.upload()

def mean_fn(index_points):
  return tf.reshape(3*index_points, shape=[int(len(index_points))/2, 2])

#data = np.array(pd.read_csv(io.BytesIO(uploaded['gyro_fake_data_v1.csv'])))
data = np.array(pd.read_csv('gyro_fake_data_v1.csv'))

tf.enable_v2_behavior()

tfb = tfp.bijectors
tfd = tfp.distributions
psd_kernels = tfp.math.psd_kernels

# observations from a known function at some random points.
a=10
Y = Y_plot = data[::a,1].reshape(-1,1)
X1 = X1_plot = data[::a,3] #rotation
X2 = X2_plot = data[::a,2] #B_V
X = np.dstack([X1, X2]).reshape(-1, 2)

observation_index_points = X 
observations = Y.T #np.dstack([y1,y2]).reshape(-1, 2)

x1_mesh, x2_mesh = np.meshgrid(X1, X2)

resolution = len(Y)
X1_test = np.linspace( np.min(X1), np.max(X1), num=resolution )
X2_test = np.linspace( np.min(X2), np.max(X2), num=resolution )
X1_test, X2_test = np.meshgrid( X1_test, X2_test )
X_test = np.dstack([X1_test, X2_test]).reshape(resolution, resolution, 2)
observation_noise_variance = np.ones(resolution)#.reshape(-1,1)

print(observation_index_points.shape, observations.shape)
amplitude = tfp.util.TransformedVariable(
  1., tfb.Exp(), dtype=tf.float64, name='amplitude')
length_scale = tfp.util.TransformedVariable(
  1., tfb.Exp(), dtype=tf.float64, name='length_scale')
kernel = psd_kernels.ExponentiatedQuadratic(
  amplitude,length_scale=10)*psd_kernels.ExponentiatedQuadratic(
    amplitude, length_scale=3)

#observation_noise_variance = tfp.util.TransformedVariable(
#    np.exp(-5), tfb.Exp(), name='observation_noise_variance')

optimizer = tf.optimizers.Adam(learning_rate=.05, beta_1=.5, beta_2=.99)

@tf.function
def optimize():
  with tf.GradientTape() as tape:
    loss = -gp.log_prob(observations)
  grads = tape.gradient(loss, gp.trainable_variables)
  optimizer.apply_gradients(zip(grads, gp.trainable_variables))
  return loss

gp = tfd.GaussianProcessRegressionModel(
    kernel=kernel,
    index_points=X_test,
    observation_index_points=X,
    observations=Y.T, observation_noise_variance = observation_noise_variance)

for i in range(100):
  neg_log_likelihood_ = optimize()
  if i % 100 == 0:
    print("Step {}: NLL = {}".format(i, neg_log_likelihood_))

samples = gp.sample(10)
var = gp.variance()
# ==> 10 independently drawn, joint samples at `index_points`.
# ==> 10 independently drawn, noisy joint samples at `index_points`

fig = plt.figure(figsize=(18, 10))
ax = plt.axes(projection='3d')
ax.view_init(0, 40)
ax.plot_surface(X1_test, X2_test, samples[9], antialiased=True, alpha=0.7, linewidth=0.5, cmap='winter')
ax.scatter3D(X1, X2, Y, marker='o',edgecolors='k', color='r', s=150)
ax.set_xlabel('B-V Index')
ax.set_ylabel('Rotation Period (Days)')
ax.set_zlabel('Age (Gyr)')

plt.show()

numElems = len(Y)
idx = np.round(np.linspace(0, len(np.array(samples[0]).reshape(numElems**2)) - 1, numElems)).astype(int)
# Picks equal spaced elements from (longer) prediction array so that its shape of data

mu_test = (np.array(samples[9]).reshape(numElems**2)[idx])
sd_test = (np.array(var).reshape(numElems**2)[idx]) 

vals = np.sort([mu_test, sd_test], axis=1)

plt.figure(figsize=(18,9))
plt.errorbar(Y, vals[0,:], yerr=vals[1,:]**2, fmt='bo')
plt.plot(np.linspace( np.min(Y), np.max(Y), num=resolution ), np.linspace( np.min(Y), np.max(Y), num=resolution ), 'r')

plt.show()

Z = (np.sort(data[::a,1])-vals[0,:])/vals[1,:]
print(Y.shape)
import seaborn as sns
plt.hist(Z, density=True, bins=8)
sns.distplot(np.random.normal(size=1000), hist=False)
plt.show()
